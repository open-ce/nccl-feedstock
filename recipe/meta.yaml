{% set name = "nccl" %}
{% set version = "2.7.8" %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  git_url: https://github.com/NVIDIA/nccl.git
  git_rev: v{{ version }}-1

build:
  number: 1
  string: cuda{{ cudatoolkit | replace(".*", "") }}_{{ PKG_BUILDNUM }}
  
requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
  host:
    - nvcc  {{ cudatoolkit }}
    - make  {{ make }}  
  run:
    - cudatoolkit  {{ cudatoolkit }}

test:
  requires:
    - cudatoolkit-dev  {{ cudatoolkit }}
    - {{ compiler('cxx') }}

about:
  home: https://github.com/NVIDIA/nccl.git
  license_file: LICENSE
  summary: NVIDIA Collective Communications Library. Implements multi-GPU and multi-node
           collective communication primitives for NVIDIA GPUs.
  description: |
    NCCL (pronounced "Nickel") is a stand-alone library of standard collective communication
    routines for GPUs, implementing all-reduce, all-gather, reduce, broadcast, and reduce-scatter.
  doc_url: https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html
  dev_url: https://github.com/NVIDIA/nccl.git

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
