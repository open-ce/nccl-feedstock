{% set name = "nccl" %}
{% set version = "2.17.1" %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  git_url: https://github.com/NVIDIA/nccl.git
  git_rev: v{{ version }}-1
  patches:                           #[cudatoolkit == '11.2']
    - 0001-fix-for-gcc-8.patch       #[cudatoolkit == '11.2']

build:
  number: 2
  string: cuda{{ cudatoolkit | replace(".*", "") }}_{{ PKG_BUILDNUM }}
  script_env:
    - CUDA_HOME
  
requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
  host:
    - make
  run:
    - cudatoolkit  {{ cudatoolkit }}

test:
  requires:
    - {{ compiler('cxx') }}

about:
  home: https://github.com/NVIDIA/nccl.git
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE.txt
  summary: NVIDIA Collective Communications Library. Implements multi-GPU and multi-node
           collective communication primitives for NVIDIA GPUs.
  description: |
    NCCL (pronounced "Nickel") is a stand-alone library of standard collective communication
    routines for GPUs, implementing all-reduce, all-gather, reduce, broadcast, and reduce-scatter.
  doc_url: https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html
  dev_url: https://github.com/NVIDIA/nccl.git

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
